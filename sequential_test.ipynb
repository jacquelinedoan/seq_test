{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacquelinedoan/seq_test/blob/main/sequential_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reinforcement Learning for Optimal Alpha Spending Function in Sequential Hypothesis Testing**\n",
        "Rambling by Jacqueline.\n",
        "\n",
        "## Introduction\n",
        "Product experiements are commonly in the form of a $z$-test (or $t$-test), comparing the 2 means of some KPI of both the control and test groups, say $\\mu_1$ and $\\mu_2$ respectively. The test is of course conducted after all data is collected. Furthermore,\n",
        "$$H_0: \\mu_1 = \\mu_2$$\n",
        "$$H_A: \\mu_1 < \\mu_2$$\n",
        "\n",
        "Given significance level $\\alpha$, if we find statistical significance, $H_0$ is rejected and we accept $H_A$; the new product is considered a success.\n",
        "*However, what happens when we do not find significance?*\n",
        "\n",
        "Say that we decided more data is needed and the data collection period is extended. Both the control and test groups grow in sample size. We then conduct the $z$-test a second time at some significance level. *Why don't we continue this process until we reached significance?*\n",
        "\n",
        "### *Sampling to reach a foregone conclusion*\n",
        "**Type I Error** (False Positive Error) is the risk of incorrectly rejecting a true $H_0$. In other words, we conclude the new version of the product is a success while it is not, risking shipping a product that does not have a positive effect on our customers.\n",
        "\n",
        "**Significance level $\\alpha$** is also the maximum probability of observing Type I Errors that the experimenter will accept in the long run.\n",
        "\n",
        "If we conduct the test once, the probability of not getting a FP error is $1-\\alpha$. If we conduct the tests above $k$ times, each at $\\alpha$, the change of observing at least one false positive grows\n",
        "$$P(\\geq 1 \\text{ FP }) = 1 - P(< 1 \\text{ FP }) = 1 - (1-\\alpha)^k$$\n",
        "\n",
        "*As $k \\to ∞$, just by chance, the probability you make at least one FP increases.*\n",
        "\n"
      ],
      "metadata": {
        "id": "r76cia6uZNko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling to reach a foregone conclusion, but formal.\n",
        "Let $X_1, X_2, \\dots \\sim N(\\mu, \\sigma^2)$ where $\\sigma^2$ is known. Consider the test of $H_0: \\mu=0$ and $H_A: \\mu\\neq 0$. Let $S_n = \\sum_{i=1}^nX_i$. Under $H_0$, $S_n \\sim N(0, n\\sigma^2)$. Thus the rejection region is such that $|S_n|>1.96\\sigma\\sqrt{n}$ for $\\alpha=0.05$. We will show that as $n\\to ∞$, or, as we keep doing more iterim tests, we will eventually (in probability) arrive at the rejection region. *The Law of Iterated Logarithm* implies that\n",
        "$$\\lim_{n\\to ∞} \\sup \\frac{S_n}{\\sigma\\sqrt{2n\\log \\log n}}=1 \\quad \\text{ with probability } 1$$\n",
        "In other words, $S_n$ is growing as fast as the denominator, which is unbounded.\n",
        "\n",
        "### Lan & DeMets (1983)\n",
        "Recall the typical 2 sample problem, where we want to compare the responses to treatments A and B, say the responses follows the distributions $N(\\mu_A, \\sigma)$ and $N(\\mu_B, \\sigma)$ respectively, and $H_0: \\mu_A = \\mu_B$. Say there are $n$ observations in each group ($2n$ observations in total), and a $z$-test is conducted. Then we reject $H_0$ if and only if\n",
        "$$Z=\\left|\\frac{\\bar{X}_A - \\bar{X}_B }{\\sqrt{2\\sigma^2/n}}\\right|>1.96$$\n",
        "\n",
        "Now, say we collect data such that once $n$ new observations are collected in each group, we conduct another $z$-test, only on the new data for the sake of independence. We will conduct $K$ tests in total, and there will be $2nK$ observations at the end. The statistic at step $j$ is\n",
        "$$Y_j = \\frac{\\bar{X}_{A_j} - \\bar{X}_{A_j}}{\\sqrt{2\\sigma^2/n}} \\sim N(\\delta^*, 1)$$\n",
        "\n",
        "where $\\delta^* = \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}$. Then $S_k = \\sum_j^kY_j \\sim N(\\sigma^*k, k)$. Then the rejection region per interim test is defined by boundaries $b_k$, namely\n",
        "$$|S_k|>b_k$$\n",
        "such that\n",
        "$$P(|S_1|\\leq b_1, \\dots, |S_K|\\leq b_K) \\leq 1-\\alpha$$\n",
        "Equivalently, let $f$ be the joint pdf of the score statistics,\n",
        "$$\\int^{b_1}_{-b_1} \\dots \\int^{b_K}_{-b_K} f(s_1, \\dots, s_K)d_{s_1}\\dots d_{s_K} = 1-\\alpha$$\n",
        "\n",
        "Lan & DeMets (1983) proposed the $\\alpha$-spending function, $\\alpha^*$, a non-decreasing function. The significance level to use at each step is $\\alpha_k = \\alpha^*(t_k) - \\alpha^*(t_{k-1})$. They went further to suggest a functional form, namely\n",
        "$$\\alpha^*(t) = \\alpha \\log (1+(e-1)t)$$\n",
        "for the set up in Pocock (1977).\n",
        "### Introduction\n",
        "Sequential tests are statistical tests to solve the problem above. Well-known techniques include group sequential tests, always valid inference, and corrected-alpha approach. Sequential testing does not required the use of RL -- the methodologies above are well-established and optimal.\n",
        "\n",
        "However, I'm particularly interested in group sequential tests as a (Constrained) Markov Decision Process. Under this view, the optimal **$\\alpha$ spending function** is the optimal policy. This is a function that spreads $\\alpha$ over the sequence of $z$-tests, say $\\alpha_1, \\dots, \\alpha_k$.\n",
        "\n",
        "One can describe what I'm doing below as this picture:\n",
        "\n",
        "![300px-Bill_Gates'_Giant_Ping_Pong_Paddle.jpg](data:image/jpeg;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9I6HwoFV33D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constrained Markov Decision Process (CMDP)\n",
        "Consider a Decision Maker (DM) who is conducting a sequence of $K$ 2-sample t-tests (unknown variance) between control and test groups with\n",
        "$$H_0: \\mu_C=\\mu_T $$\n",
        "$$H_A: \\mu_C < \\mu_T$$\n",
        "At each test $k$, the DM has 3 actions:\n",
        "* Stop and Reject. If $H_A$ is true: $+R_{TP} = 1$\n",
        "* Stop and Reject. If $H_0$ is true: $-R_{FP} = -1$\n",
        "* Continue Sampling: $-c$ for sampling cost\n",
        "\n",
        "At the terminal state $K$, the DM stops and accepts.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "4VdyTo_gXLtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "lxlVfH2xXDcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to simulate the sequential tests\n",
        "class SequentialTEnv:\n",
        "    def __init__(self,\n",
        "                 mu0=0.0,\n",
        "                 mu1=0.5,\n",
        "                 sigma=1.0,\n",
        "                 alpha=0.05,\n",
        "                 max_looks=50,\n",
        "                 batch_size=10,\n",
        "                 mc_precompute_n=5000,\n",
        "                 seed=None):\n",
        "        self.mu0 = mu0 # control group\n",
        "        self.mu1 = mu1 # test group\n",
        "        self.sigma = sigma\n",
        "        self.alpha = alpha\n",
        "        self.max_looks = max_looks\n",
        "        self.batch_size = batch_size\n",
        "        self.mc_precompute_n = mc_precompute_n\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self,\n",
        "              hypothesis=None):\n",
        "        # reseting for a new experiement\n",
        "        if hypothesis is not None:\n",
        "            self.hypothesis = hypothesis\n",
        "        else:\n",
        "            self.hypothesis = self.rng.choice([0, 1])\n",
        "        self.n_seen = 0\n",
        "        self.alpha_rem = self.alpha\n",
        "        self.done = False\n",
        "        self.history = []\n",
        "        return self._get_state()\n",
        "\n",
        "    def _sample_batch(self):\n",
        "        # Simulate the batch of control and test subjects\n",
        "        x_c = self.rng.normal(self.mu0,\n",
        "                              self.sigma,\n",
        "                              self.batch_size)\n",
        "        mu = self.mu0 if self.hypothesis == 0 else self.mu1\n",
        "        x_t = self.rng.normal(mu,\n",
        "                              self.sigma,\n",
        "                              self.batch_size)\n",
        "\n",
        "        return x_c, x_t\n",
        "\n",
        "    def _get_state(self):\n",
        "        # % seen, out of max subjects\n",
        "        frac_n = self.n_seen / (self.max_looks * self.batch_size)\n",
        "        # % alpha remaining\n",
        "        frac_alpha = self.alpha_rem / self.alpha\n",
        "        return np.array([frac_n, frac_alpha], dtype=np.float32)\n",
        "\n",
        "    def _ttest(self, x_c, x_t):\n",
        "        # calculate the t statistic\n",
        "        n1, n2 = len(x_c), len(x_t)\n",
        "        mean1, mean2 = np.mean(x_c), np.mean(x_t)\n",
        "        var1, var2 = np.var(x_c, ddof=1), np.var(x_t, ddof=1)\n",
        "        # estimate variance\n",
        "        se = np.sqrt(var1/n1 + var2/n2)\n",
        "        t_stat = (mean1 - mean2) / se\n",
        "        df_num = (var1/n1 + var2/n2)**2\n",
        "        df_den = (var1**2 / ((n1**2)*(n1-1))) + (var2**2 / ((n2**2)*(n2-1)))\n",
        "        df = df_num / df_den\n",
        "        from scipy.stats import t\n",
        "        p_val = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "        return t_stat, p_val\n",
        "\n",
        "    def step(self, action):\n",
        "        # Action = fraction of remaining alpha to spend\n",
        "        frac = np.clip(action, 0.0, 1.0)\n",
        "        # spend alpha\n",
        "        spend = frac * self.alpha_rem\n",
        "        spend = min(spend, self.alpha_rem)\n",
        "        self.alpha_rem -= spend\n",
        "\n",
        "        # Draw new batch\n",
        "        x_c, x_t = self._sample_batch()\n",
        "        self.n_seen += self.batch_size\n",
        "\n",
        "        # Pooled variance, Welch's t\n",
        "        t_stat, p_val = self._ttest(x_c, x_t)\n",
        "\n",
        "        reward, cost = 0.0, 0.0 # initialize\n",
        "        if p_val < spend:\n",
        "            self.done = True\n",
        "            if self.hypothesis == 1:\n",
        "                reward = 1.0  # true positive\n",
        "            else:\n",
        "                cost = 1.0    # false positive\n",
        "        elif self.n_seen >= self.max_looks * self.batch_size or self.alpha_rem <= 1e-12:\n",
        "            self.done = True\n",
        "\n",
        "        return self._get_state(), reward, cost, self.done\n",
        "\n"
      ],
      "metadata": {
        "id": "tQdtMt11Ozz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Framing the problem as a CMDP, our goal is to maximize power (probability of correct rejection) while under the constraint that the False Positive Rate is bounded by $\\alpha$.\n",
        "$$ P(\\text{ Reject } H_0 | H_0 \\text{ true })\\leq \\alpha$$\n",
        "\n",
        "The **objective function** is then,\n",
        "$$J(\\pi) = E_\\pi(\\text{Power}) \\quad \\text{ s.t. } \\quad  E_\\pi(\\text{Type I Error}) \\leq \\alpha $$\n",
        "The objective function is also optimized for power if we optimize for utility (reward). Equivalently,\n",
        "$$J(\\pi)= E_{H_A}(\\text{Utility}) \\quad \\text{ s.t. } \\quad E_{H_0}(1\\{\\text{Reject}\\}) \\leq \\alpha $$\n",
        "\n",
        "This is a contrained optimizatio problem, so we use **Lagrangian Multiplier** to formulate it into a saddle optimization problem:\n",
        "$$L(\\pi, \\lambda) = J(\\pi) - \\lambda\\times(E_{H_0}(\\text{Reject}) - \\alpha )$$\n",
        "We optimize $L$ by  **Primal-Dual Alogrithm**, i.e., iteratively\n",
        "\n",
        "1.   *Policy Update*: Maximize $J(\\pi)$ via Proximal Policy Optimization (PPO)\n",
        "2.   *Multiplier Update*: Minimize $- \\lambda\\times(E_{H_0}(\\text{Reject}) - \\alpha )$ via dual ascent algoritm for constraint\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "smv7RvL3XDyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PPO requires 2 NN, Actor (Policy Net) and Critic (Value Net)\n",
        "\n",
        "# PolicyNet:\n",
        "# Input: current state (_get_state output)\n",
        "# Output: prob dist over possible actions (possible alpha fraction spend)\n",
        "\n",
        "\n",
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self, state_dim=2, hidden=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.mu = nn.Linear(hidden, 1)\n",
        "        self.log_std = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        mu = torch.sigmoid(self.mu(h))  # action in [0,1]\n",
        "        std = torch.exp(self.log_std)\n",
        "        return mu, std # of action distribution\n",
        "\n",
        "    def sample(self, x):\n",
        "      # sample action\n",
        "        mu, std = self(x)\n",
        "        dist = torch.distributions.Normal(mu, std)\n",
        "        action = torch.clamp(dist.sample(), 0.0, 1.0)\n",
        "        log_prob = dist.log_prob(action)\n",
        "        return action, log_prob\n",
        "\n",
        "# ValueNet:\n",
        "# Input: current state\n",
        "# Output: expected cumulative reward\n",
        "\n",
        "class ValueNet(nn.Module):\n",
        "    def __init__(self, state_dim=2, hidden=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.v = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.v(h)"
      ],
      "metadata": {
        "id": "wK2-FiTGXFm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primal-dual update\n",
        "\n",
        "def run_training(config):\n",
        "    # Initialization\n",
        "    env = SequentialTEnv(alpha=config['alpha'],\n",
        "                        max_looks=config['max_looks'],\n",
        "                        batch_size=config['batch_size'])\n",
        "\n",
        "    policy = PolicyNet()\n",
        "    value = ValueNet()\n",
        "    opt_pi = optim.Adam(policy.parameters(), lr=config['lr'])\n",
        "    opt_v = optim.Adam(value.parameters(), lr=config['lr'])\n",
        "\n",
        "    lambda_dual = torch.tensor(1.0, requires_grad=False)\n",
        "\n",
        "    # Training Loop\n",
        "    for it in range(config['train_iters']):\n",
        "        batch = []\n",
        "        for ep in range(config['batch_episodes']):\n",
        "            s = env.reset()\n",
        "            done = False\n",
        "            ep_reward, ep_cost = 0.0, 0.0\n",
        "            log_probs, states, actions = [], [], []\n",
        "\n",
        "            while not done:\n",
        "                st = torch.tensor(s, dtype=torch.float32).unsqueeze(0)\n",
        "                a, logp = policy.sample(st)\n",
        "                s_next, r, c, done = env.step(a.item())\n",
        "\n",
        "                log_probs.append(logp)\n",
        "                states.append(st)\n",
        "                actions.append(a)\n",
        "                ep_reward += r\n",
        "                ep_cost += c\n",
        "                s = s_next\n",
        "\n",
        "            batch.append((ep_reward, ep_cost, torch.stack(log_probs)))\n",
        "\n",
        "        # Compute averages\n",
        "        rewards = np.array([b[0] for b in batch])\n",
        "        costs = np.array([b[1] for b in batch])\n",
        "        avg_reward = rewards.mean()\n",
        "        avg_cost = costs.mean()\n",
        "\n",
        "        # Dual update\n",
        "        lambda_dual = torch.clamp(lambda_dual + config['lr_dual'] * (avg_cost - config['alpha']), min=0.0)\n",
        "\n",
        "        # Policy update (surrogate loss)\n",
        "        L_terms = []\n",
        "        for R, C, logps in batch:\n",
        "            L_terms.append((R - lambda_dual.item() * C) * logps.sum())\n",
        "        loss_pi = -torch.stack(L_terms).mean()\n",
        "\n",
        "        opt_pi.zero_grad()\n",
        "        loss_pi.backward()\n",
        "        opt_pi.step()\n",
        "\n",
        "        # Logging\n",
        "        if it % 10 == 0:\n",
        "            print(f\"Iter {it}: reward={avg_reward:.3f}, cost={avg_cost:.3f}, lambda={lambda_dual.item():.3f}\")\n",
        "\n",
        "    return policy, value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z9DOsrqmT-qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_CONFIG = {\n",
        "    'alpha': 0.05,\n",
        "    'max_looks': 20,\n",
        "    'batch_size': 10,\n",
        "    'lr': 1e-3,\n",
        "    'lr_dual': 1e-2,\n",
        "    'train_iters': 200, # num times NN weights are updated\n",
        "    'batch_episodes': 50, # in each train iter, experiments repetition\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    policy, value = run_training(DEFAULT_CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhqxhuwIUAdu",
        "outputId": "5027d0d4-b0e2-49b2-c092-b8feba347c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: reward=0.140, cost=0.040, lambda=1.000\n",
            "Iter 10: reward=0.080, cost=0.000, lambda=0.997\n",
            "Iter 20: reward=0.100, cost=0.000, lambda=0.994\n",
            "Iter 30: reward=0.060, cost=0.020, lambda=0.991\n",
            "Iter 40: reward=0.060, cost=0.020, lambda=0.989\n",
            "Iter 50: reward=0.080, cost=0.040, lambda=0.986\n",
            "Iter 60: reward=0.140, cost=0.020, lambda=0.983\n",
            "Iter 70: reward=0.080, cost=0.020, lambda=0.981\n",
            "Iter 80: reward=0.100, cost=0.020, lambda=0.980\n",
            "Iter 90: reward=0.120, cost=0.000, lambda=0.977\n",
            "Iter 100: reward=0.080, cost=0.020, lambda=0.975\n",
            "Iter 110: reward=0.060, cost=0.040, lambda=0.972\n",
            "Iter 120: reward=0.080, cost=0.040, lambda=0.969\n",
            "Iter 130: reward=0.180, cost=0.020, lambda=0.967\n",
            "Iter 140: reward=0.120, cost=0.020, lambda=0.965\n",
            "Iter 150: reward=0.100, cost=0.020, lambda=0.962\n",
            "Iter 160: reward=0.080, cost=0.020, lambda=0.959\n",
            "Iter 170: reward=0.000, cost=0.000, lambda=0.955\n",
            "Iter 180: reward=0.080, cost=0.000, lambda=0.953\n",
            "Iter 190: reward=0.100, cost=0.020, lambda=0.950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBWTw-KAWcQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}